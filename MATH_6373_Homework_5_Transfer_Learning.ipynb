{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ethanmarshallanalytics/Deep-Learning-and-Neural-Networks/blob/main/MATH_6373_Homework_5_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "%ls\n",
        "%cd drive\n",
        "%ls\n",
        "%cd MyDrive/\n",
        "%ls\n",
        "\n"
      ],
      "metadata": {
        "id": "8p6pY7XtP2YG",
        "outputId": "9b10d2de-919c-4591-f523-35988a97de06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n",
            "/content/drive\n",
            "\u001b[0m\u001b[01;34mMyDrive\u001b[0m/\n",
            "/content/drive/MyDrive\n",
            "unzip:  cannot find or open /content/drive/MyDrive/cat_v1.zip, /content/drive/MyDrive/cat_v1.zip.zip or /content/drive/MyDrive/cat_v1.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "id": "AAx7R_LxFXPN",
        "outputId": "2dc6aa80-a94b-44bc-a4ff-f47572a60d58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'2020 Qualified Athletes.gsheet'   IMG_4126.MOV\n",
            " Bracketology.gsheet               irisData.csv\n",
            " \u001b[0m\u001b[01;34mcat_v1\u001b[0m/                          'Jersey Boys Restaurant.gdoc'\n",
            "\u001b[01;34m'cat_v1 (2)'\u001b[0m/                     'NBA Team Roster.gsheet'\n",
            "'Classic Rock .gsheet'            \u001b[01;34m'NCAA College Basketball'\u001b[0m/\n",
            "\u001b[01;34m'Colab Notebooks'\u001b[0m/                'Red Sox 2019 Depthhart.gsheet'\n",
            "'Copy of IMG_1749.MOV'            'Summer Training Program.gsheet'\n",
            "'Course Schedule.gsheet'           sWOlmDz8RE.mp4\n",
            "'Courses Spring 2020.gsheet'      'Untitled document.gdoc'\n",
            " \u001b[01;34mCS167\u001b[0m/                           'Untitled spreadsheet.gsheet'\n",
            " dTE2Q1buUf.mp4                   'USA Outdoor Championship Qualifiers.gsheet'\n",
            "'Getting started.pdf'              vxCAsrg4Bg.mp4\n",
            " image.jpg                         \u001b[01;34mZipShare\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "dataset = torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/cats-breed-dataset/', transform=preprocess)\n",
        "dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "RBTpb68SEvOH",
        "outputId": "30bf8a4c-eb03-4c08-d55a-39646c62a067",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 298\n",
              "    Root location: /content/drive/MyDrive/cats-breed-dataset/\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               Resize(size=256, interpolation=bilinear, max_size=None, antialias=True)\n",
              "               CenterCrop(size=(224, 224))\n",
              "               ToTensor()\n",
              "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGAASfw8mBu-",
        "outputId": "45d0ff76-262f-4f62-85d1-1f91ada73786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:03<00:00, 80.2MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_loader' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bd453a0a1a00>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pre-trained AlexNet model\n",
        "model = torchvision.models.alexnet(pretrained=True)\n",
        "\n",
        "# Freeze the parameters of the feature extraction layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the last fully connected layer for 5 classes\n",
        "num_features = model.classifier[6].in_features\n",
        "model.classifier[6] = nn.Linear(num_features, 5)\n",
        "\n",
        "# Move the model to GPU if available\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Load Cats breed dataset and split into train and test sets\n",
        "# Assuming you have already downloaded and organized the dataset\n",
        "# You need to define the dataset loading part accordingly\n",
        "\n",
        "# Assuming train_loader and test_loader are PyTorch DataLoader objects\n",
        "\n",
        "# Define the number of epochs\n",
        "num_epochs = 10\n",
        "\n",
        "# Lists to store training and testing loss, and testing accuracy\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "test_accuracy_history = []\n",
        "\n",
        "# Training the model\n",
        "for epoch in range(num_epochs):\n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Compute average training loss for the epoch\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_loss_history.append(train_loss)\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Evaluate on test set\n",
        "    test_running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_running_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Compute average testing loss and accuracy for the epoch\n",
        "    test_loss = test_running_loss / len(test_loader)\n",
        "    test_loss_history.append(test_loss)\n",
        "    accuracy = correct / total * 100\n",
        "    test_accuracy_history.append(accuracy)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
        "          f\"Train Loss: {train_loss:.4f}, \"\n",
        "          f\"Test Loss: {test_loss:.4f}, \"\n",
        "          f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Plotting training and test loss\n",
        "plt.plot(range(1, num_epochs+1), train_loss_history, label='Training Loss')\n",
        "plt.plot(range(1, num_epochs+1), test_loss_history, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Test Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plotting test accuracy\n",
        "plt.plot(range(1, num_epochs+1), test_accuracy_history, label='Test Accuracy', color='green')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Test Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ]
}